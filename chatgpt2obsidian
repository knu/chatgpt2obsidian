#!/usr/bin/env ruby
#
# chatgpt2obsidian - Converts ChatGPT conversations to Markdown files for Obsidian
#
# Copyright (c) 2025 Akinori Musha
#
# All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions
# are met:
# 1. Redistributions of source code must retain the above copyright
#    notice, this list of conditions and the following disclaimer.
# 2. Redistributions in binary form must reproduce the above copyright
#    notice, this list of conditions and the following disclaimer in the
#    documentation and/or other materials provided with the distribution.
#
# THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS ``AS IS'' AND
# ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
# ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE
# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
# OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
# HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
# LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
# OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
# SUCH DAMAGE.

require "bundler/inline"

gemfile do
  source "https://rubygems.org"
  gem "rubyzip"
  gem "debug" if ENV["DEBUG"]
end

require "cgi"
require "debug" if ENV["DEBUG"]
require "digest"
require "fileutils"
require "json"
require "optparse"
require "stringio"
require "tempfile"
require "time"
require "uri"
require "yaml"
require "zip"

class Time
  def encode_with(coder)
    coder.represent_scalar(nil, iso8601)
  end
end

def slugify(str)
  s = str.gsub(/[\x00-\x1F<>:"\/\\|?*.]/, "_")
  s.strip!
  s.gsub!(/\s+/, " ")
  s.gsub!(/\A\.+/, "_")
  s
end

module MD
  module_function

  def escape_link_text(text)
    text.strip.gsub(/([\\\[\]*_`~\n])/, '\\\\\\1')
  end

  def escape_href(href)
    if href.match?(/\A(?<p>(?:(?~[()])|\(\g<p>\))*)\z/)
      href
    else
      href.gsub(/[()]+/) { CGI.escape(it) }
    end
  end

  def escape_title(title)
    title = title.strip

    if title.match?(/[\\'"()\s]/)
      escaped = title
        .gsub(/([\\"])/, "\\\\\\1")
        .gsub(/\n(?:[ \f\r\t\v]*\n)+/, "\n")

      "\"#{escaped}\""
    else
      title
    end
  end

  def linked_text(text:, href:, title: nil)
    if title
      "[#{escape_link_text(text)}](#{escape_href(href)} #{escape_title(title)})"
    else
      "[#{escape_link_text(text)}](#{escape_href(href)})"
    end
  end

  def image(src:, alt: nil, title: nil)
    "!#{linked_text(text: alt || "", href: src, title:)}"
  end

  def linked_image(src:, href:, alt: nil, title: nil, link_title: nil)
    if link_title
      "[#{image(alt:, src:, title:)}](#{escape_href(href)} #{escape_title(link_title)})"
    else
      "[#{image(alt:, src:, title:)}](#{escape_href(href)})"
    end
  end
end

class BufferedLinePrinter < StringIO
  attr_reader :device, :indent

  def initialize(device)
    super()
    @device = device
    @indent = []
  end

  def indent(str, &block)
    @indent.unshift(str)
    if block
      begin
        yield
      ensure
        dedent
      end
    end
    self
  end

  def dedent
    @indent.shift
    self
  end

  def puts(*lines)
    if @indent.empty?
      super
    elsif lines.empty?
      super @indent.join
    else
      super lines.flatten.flat_map { it.split(/^/).map { "#{@indent.join}#{it}" } }
    end
  end

  def empty?
    pos == 0
  end

  def flush(&block)
    return "" if empty?

    output = block ? block.call(string) : string
    @device.puts(output)
    self.string = ""
    output
  end
end

class ChatGPT2Obsidian
  attr_reader :attachments_subdirectory, :created_key, :updated_key, :json_output_directory

  def self.run(argv = ARGV)
    new.run(argv)
  end

  def initialize
    @attachments_subdirectory = "attachments"
    @created_key = "created"
    @updated_key = "updated"
    @json_output_directory = nil
    @export_dir_is_temp = false
    @export_dir = nil
  end

  def load_existing_file_info
    mapping = {}
    Dir.glob(File.join(@output_directory, "*.md")) do |file|
      content = File.read(file)
      sha256sum = Digest::SHA256.hexdigest(content)
      yaml_body = content[/\A---\n(?~^---$)\n/m]
      frontmatter =
        if yaml_body
          begin
            YAML.safe_load(yaml_body, permitted_classes: [Date, Time, Symbol])
          rescue StandardError => e
            warn "Failed to parse frontmatter in #{file}: #{e.message}"
            {}
          end
        else
          {}
        end
      cid = frontmatter["conversation_id"] or next

      mapping[cid] = { file:, frontmatter:, sha256sum: }
    end
    mapping
  end

  def parse_options(argv)
    parser = OptionParser.new do |opts|
      opts.banner = <<~BANNER
        Usage: #{$0} [options] <input_path> <output_directory>

            <input_path>: ChatGPT export zip file or its extracted directory
            <output_directory>: Directory where converted Markdown files will be saved
      BANNER

      opts.on("-a", "--attachments-subdirectory NAME",
              "Specify attachments subdirectory name (default: attachments)") do |name|
        @attachments_subdirectory = name
      end

      opts.on("-c", "--created-key KEY",
              "Specify the frontmatter key for created timestamp (default: created)") do |key|
        @created_key = key
      end

      opts.on("-u", "--updated-key KEY",
              "Specify the frontmatter key for updated timestamp (default: updated)") do |key|
        @updated_key = key
      end

      opts.on("-j", "--json-output DIR",
              "Output raw JSON files to the specified directory") do |dir|
        @json_output_directory = dir
      end

      opts.on("-h", "--help", "Show this message") do
        puts opts
        exit
      end
    end

    begin
      remaining_argv = parser.parse(argv)
    rescue OptionParser::InvalidOption => e
      warn e.message
      warn parser.help
      exit 1
    end

    if remaining_argv.size != 2
      warn parser.help
      exit 1
    end

    @input_path, @output_directory = remaining_argv
  end

  def load_data(input_path)
    if File.directory?(input_path)
      @export_dir = input_path
    elsif input_path.downcase.end_with?(".zip") && File.exist?(input_path)
      @export_dir = Dir.mktmpdir(File.basename($0))
      @export_dir_is_temp = true

      Zip::File.open(input_path) do |zip_file|
        zip_file.each do |entry|
          case name = entry.name
          when %r{\A/|(?:/|\A)\.\.(?:/|\z)}
            warn "Skipping an invalid entry: #{entry.name}"
          else
            dir = File.dirname(File.join(@export_dir, name))
            FileUtils.mkdir_p(dir)
            entry.extract(destination_directory: @export_dir)
          end
        end
      end
    else
      raise "Input path must be a ZIP file or directory containing conversations.json"
    end

    conversations_json = File.join(@export_dir, "conversations.json")

    if File.file?(conversations_json)
      conversations = JSON.parse(File.read(conversations_json), symbolize_names: true)
    else
      raise "conversations.json is not found in #{input_path}"
    end

    chat_html = File.join(@export_dir, "chat.html")

    if File.file?(chat_html)
      assets = File.open(chat_html) { |f|
        f.each_line { |line|
          json = line[/ assetsJson = \K\{.+\}/] and
            break JSON.parse(json)
        }
      }
    else
      raise "chat.html is not found in #{input_path}"
    end

    {
      conversations:,
      assets:,
    }
  end

  def run(argv = ARGV)
    parse_options(argv)
    load_data(@input_path) => { conversations:, assets: }

    FileUtils.mkdir_p(@output_directory)
    FileUtils.mkdir_p(@json_output_directory) if @json_output_directory

    conversations.sort_by {
      it[:create_time]
    }.each do |conversation|
      process_conversation(conversation, assets)
    end
  ensure
    FileUtils.rm_rf(@export_dir) if @export_dir_is_temp
  end

  private

  def existing_file_info = @existing_file_info ||= load_existing_file_info

  def process_conversation(conversation, assets)
    conversation => { title:, conversation_id:, create_time:, update_time: }
    created = Time.at(create_time)
    updated = Time.at(update_time)
    conversation_url = "https://chat.openai.com/c/#{conversation_id}"

    target = determine_target_file(title, conversation_id)

    if @json_output_directory
      json_file = File.join(@json_output_directory, "#{File.basename(target, ".md")}.json")
      File.write(json_file, JSON.pretty_generate(conversation))
    end

    mapping = conversation[:mapping] || {}
    root_id = mapping.find { |_, v| v[:parent].nil? }&.first
    return unless root_id

    order = []

    # Find the latest timestamp in a subtree
    find_latest_timestamp = ->(mapping, node) {
      entry = mapping[node] or return 0

      entry[:children]&.map { |child|
        find_latest_timestamp.call(mapping, child.to_sym)
      }&.max || entry.dig(:message, :create_time) || 0
    }

    # Find the main conversation path by selecting the most recent branch at each split
    find_main_path = ->(node) {
      if mapping[node] in { children: }
        case children.map(&:to_sym)
        in []
        in [child]
          order << child
          find_main_path.call(child)
        in _ => children
          newest_child = children.max_by { |child|
            find_latest_timestamp.call(mapping, child)
          }

          order << newest_child
          find_main_path.call(newest_child)
        end
      end
    }

    find_main_path.call(root_id.to_sym)

    models = order.filter_map { |msg_id|
      mapping[msg_id].dig(:message, :metadata, :model_slug)
    }.uniq

    Tempfile.create(["chatgpt_", ".md"]) do |temp_file|
      md = BufferedLinePrinter.new(temp_file)

      frontmatter = {
        "title"            => title,
        @created_key       => created,
        @updated_key       => updated,
        "conversation_id"  => conversation_id,
        "conversation_url" => conversation_url,
        "models"           => models,
      }

      case existing_file_info[conversation_id]
      in nil
      in { frontmatter: existing_frontmatter }
        frontmatter.update(existing_frontmatter.except(*frontmatter.keys))
      end

      md.puts YAML.dump(frontmatter)
      md.puts "---"

      type = last_type = nil

      order.each do |msg_id|
        entry = mapping[msg_id]
        entry => { message: { author:, content: } }
        author => { role: }
        content => { content_type: }

        next if content_type == "user_editable_context"

        buf = BufferedLinePrinter.new(md)

        begin
          type = process_message_entry(buf, entry, assets:) or next

          case
          when type == :user && last_type != :user
            md.puts if last_type
            md.puts "# User"
          when type != :user && last_type == :user
            md.puts if last_type
            md.puts "# ChatGPT"
          end

          case type
          in :process
            if last_type == :process
              md.indent("> ") do
                md.puts

                buf.rewind
                buf.write buf.string.sub(/\A(?~^```)^> \[!abstract\]- Thoughts\n((?:> .*\n)+)/) {
                  $1.gsub(/^> /, "")
                }
                buf.truncate(buf.tell)
                buf.flush
              end
            else
              buf.flush
            end
          else
            md.puts if last_type
            buf.flush
          end

          last_type = type
        rescue => e
          raise "#{e.message}: #{title}"
        end
      end

      md.flush
      temp_file.close

      case existing_file_info[conversation_id]
      in nil
      in { file: existing_file, sha256sum: existing_sha256sum }
        if existing_file != target
          if existing_file.unicode_normalize(:nfc) != target
            # Only notify when they differ in their normalized form,
            # because renaming may otherwise be a no-op on a
            # filesystem that performs automatic normalization.
            puts "Renaming #{existing_file} to #{target}"
          end
          File.rename(existing_file, target)
        end
      end

      sha256sum = Digest::SHA256.file(temp_file.path).hexdigest

      if !existing_sha256sum || existing_sha256sum != sha256sum
        FileUtils.cp(temp_file.path, target)
        puts "Written #{target}"
      end

      existing_file_info[conversation_id] = { file: target, sha256sum: }
    end
  end

  def determine_target_file(title, conversation_id)
    basename =
      case slugify(title)
      in /./ => str
        str.unicode_normalize(:nfc)
      else
        conversation_id
      end

    target = File.join(@output_directory, "#{basename}.md")

    original_basename = basename
    counter = 1
    while existing_file_info.any? { |key, value| key != conversation_id && value[:file] == target }
      basename = "#{original_basename}_#{counter}"
      target = File.join(@output_directory, "#{basename}.md")
      counter += 1
    end

    target
  end

  def process_asset_file(buf, assets, asset_pointer)
    asset_file = assets.fetch(asset_pointer) {
      warn "Skipped a missing asset file: #{asset_pointer}"
      return
    }
    asset_file_name = File.basename(asset_file)
    source_path = File.join(@export_dir, asset_file)
    target_dir = File.join(@output_directory, @attachments_subdirectory)
    target_path = File.join(target_dir, asset_file_name)
    unless File.exist?(target_path) && FileUtils.identical?(source_path, target_path)
      FileUtils.mkdir_p(target_dir)
      FileUtils.cp(source_path, target_path, verbose: true)
    end
    buf.puts MD.image(src: File.join(@attachments_subdirectory, asset_file_name))
  end

  def process_message_entry(buf, entry, assets:)
    entry => { message: { author:, content:, metadata:, recipient: } }
    author => { role: }
    content => { content_type: }

    case [role, content_type]
    in [_, "user_editable_context" | "app_pairing_content"]
      process_context_message(buf, entry, assets:)
    in ["user", _]
      process_user_message(buf, entry, assets:)
    else
      process_agent_message(buf, entry, assets:)
    end
  end

  def process_user_message(buf, entry, assets:)
    entry => { message: { content:, recipient: } }
    content => { content_type: }

    case content_type
    in "text"
      case recipient
      in "all" | "bio"
        buf.puts content.fetch(:parts).reject(&:empty?)
      else
        return nil
      end
    in "multimodal_text"
      entry => { message: { metadata: } }
      metadata in { attachments: } or attachments = {}

      content.fetch(:parts).each do |part|
        case part
        in String
          buf.puts part
        in { content_type: "image_asset_pointer", asset_pointer: }
          process_asset_file(buf, assets, asset_pointer)
        else
          raise "Unknown part type: #{part.inspect}"
        end
      end
    else
      pp entry
      raise "Unknown content type `#{content_type}` for user message"
    end

    :user
  end

  def process_context_message(buf, entry, assets:)
    entry => { message: { content:, metadata: } }
    content => { content_type: }

    case content_type
    in "user_editable_context"
      return nil
    in "app_pairing_content"
      metadata => { app_pairing: { shared_workspaces: } }

      shared_workspaces.each_with_index do |workspace, i|
        workspace => { id: workspace_id, app_name:, title: }
        content => { context_parts:, custom_instructions: }

        if context_parts
          context_part = context_parts.find { |part| part[:workspace_id] == workspace_id }
          context_part in { text: } or next
        else
          custom_instructions => /./ => text
        end

        buf.puts if i > 0

        buf.indent("> ") do
          buf.puts "[!quote]- Looked at #{app_name}"
          buf.puts "#### #{title}"
          buf.puts "```"
          buf.puts text
          buf.puts "```"
        end
      end
    else
      pp entry
      raise "Unknown content type `#{content_type}` for context message"
    end

    :context
  end

  def process_agent_message(buf, entry, assets:)
    entry => { message: { author:, content:, metadata:, recipient: } }
    author => { role: }
    content => { content_type: }

    web_search = false
    output_type = :response

    # Metadata processing
    case role
    in "assistant"
      # Nothing particular
    in "tool"
      case metadata
      in { search_result_groups: }
        output_type = :process
        buf.indent("> ") do
          subbuf = BufferedLinePrinter.new(buf)
          domains = Set[]

          search_result_groups.each_with_index do |group, i|
            group => { type: "search_result_group", domain:, entries: }
            domains << domain

            subbuf.puts if i > 0

            subbuf.indent("> ") do
              subbuf.puts "[!info] #{domain}"

              entries.each do |entry|
                entry => { type: "search_result", title:, url:, snippet: }
                subbuf.puts "- " + MD.linked_text(text: title, href: url, title: snippet)
              end
            end
          end

          buf.puts "[!abstract]- Search Results: #{domains.map { "[#{it}]" }.join(" ")}"
          subbuf.flush
        end
      in { async_task_type: "research", async_task_title:, async_task_prompt: }
        output_type = :process
        buf.indent("> ")
        buf.puts "[!abstract]- #{async_task_title}"
        buf.puts async_task_prompt
      in { finished_text: } if (headline = metadata[:summarization_headline] || metadata[:initial_text])
        case content
        in { content_type: "text", parts: } if parts.any?(/./)
          output_type = :process
          buf.indent("> ")
          buf.puts "[!abstract]- #{headline}"
          buf.puts finished_text
        else
          return nil
        end
      in _ if author in { name: "web.search" }
        web_search = true
      in _ if metadata in { is_visually_hidden_from_conversation: true }
        return nil
      in _ if author in { name: "bio" | "canmore.create_textdoc" | "canmore.update_textdoc" }
        return nil
      in _ if content in { content_type: "execution_output" }
        return nil
      else
        # ok
      end
    in "system"
      return nil if metadata in { is_visually_hidden_from_conversation: true }

      pp entry
      raise "Unexpected system message with unhidden content"
    else
      pp entry
      raise "Unknown role `#{role}` for agent message"
    end

    # Content processing
    case content_type
    in "text"
      if web_search
        output_type = :process
        buf.indent("> ") do
          buf.puts "[!info]- Web Search"
          buf.puts content.fetch(:parts).reject(&:empty?)
        end
      else
        case recipient
        in "all" | "bio"
          subbuf = BufferedLinePrinter.new(buf)
          subbuf.puts replace_codes(content.fetch(:parts).reject(&:empty?), metadata)

          unless subbuf.empty?
            if metadata in { model_slug: }
              buf.puts "> [!tip] #{model_slug}"
              buf.puts
            end
            subbuf.flush
          end
        else
          return nil
        end
      end
    in "multimodal_text"
      metadata in { attachments: } or attachments = {}

      content.fetch(:parts).each do |part|
        case part
        in String
          buf.puts part
        in { content_type: "image_asset_pointer", asset_pointer: }
          process_asset_file(buf, assets, asset_pointer)
        else
          raise "Unknown part type: #{part.inspect}"
        end
      end
    in "sonic_webpage"
      output_type = :process
      content => { url:, title:, domain:, text: }
      buf.indent("> ") do
        buf.puts "[!info]- Web Search: #{domain}"
        buf.puts "#### #{MD.linked_text(text: title, href: url)}"
        buf.puts text
      end
    in "thoughts"
      output_type = :process
      content => { thoughts: }
      buf.indent("> ") do
        buf.puts "[!abstract]- Thoughts"
        thoughts.each_with_index do |thought, i|
          buf.puts if i > 0
          buf.puts thought.fetch(:content)
        end
      end
    in "code"
      case metadata
      in { search_queries: }
        output_type = :process
        buf.indent("> ") do
          queries = search_queries.map { |search_query|
            search_query => { type: "search", q: }
            "[#{q}]"
          }.join(" ")

          buf.puts "[!info]- Web Search: #{queries}"
          buf.puts
        end
      else
        return nil
      end
    in "reasoning_recap"
      output_type = :process
      buf.indent("> ") do
        buf.puts "[!info]- #{content.fetch(:content)}"
      end
    else
      pp entry
      raise "Unknown content type `#{content_type}` for agent message"
    end

    output_type
  end

  def normalize_code(code)
    # Normalize a code for comparison; some types of codes that appear
    # as inline text in `parts` are inconsistent with their
    # definitions represented in the `matched_text` key.
    case code
    in /\u{E200}(products)\u{E202}(.*?)\u{E201}/
      # The product titles don't match, so omit them.
      [$1, JSON.parse($2)["selections"].map { it[0] }].join(":")
    in /\u{E200}(product_entity)\u{E202}(.*?)\u{E201}/
      # The product title doesn't match, so omit it.
      [$1, JSON.parse($2)[0]].join(":")
    else
      code
    end
  end

  def build_code_replacement_map(metadata)
    metadata in { content_references: } or return {}

    content_references.each.with_object({}) { |ref, map|
      case ref
      in { type: "grouped_webpages" | "grouped_webpages_model_predicted_fallback", matched_text:, items: }
        links = items.map { |item|
          item => { url:, title: }
          "\\[#{MD.linked_text(text: title, href: url)}\\]"
        }

        map[normalize_code(matched_text)] = links.join(" ")
      in { type: "products", matched_text:, alt:, products: }
        buf = BufferedLinePrinter.new(StringIO.new)

        headers = products.map { |product|
          product => { featured_tag:, image_urls: }
          header_parts = []

          if image_urls
            header_parts << image_urls.map { |img_url|
              MD.image(src: img_url, alt: product[:title])
            }.join(" ")
          end

          if featured_tag in /./
            header_parts << featured_tag
          end

          header_parts.join("<br>")
        }
        buf.puts "| #{headers.join(" | ")} |"
        buf.puts "| #{headers.map { "---" }.join(" | ")} |"

        cells = products.map { |product|
          product => { title:, url:, merchants:, price:, featured_tag:, image_urls:, rating:, num_reviews: }

          cell_buf = BufferedLinePrinter.new(StringIO.new)

          cell_buf.puts "**#{MD.linked_text(text: title, href: url)}**"

          if rating
            stars = rating.to_i
            cell_buf.puts "#{"★" * stars}#{"☆" * (5 - stars)} #{rating} (#{num_reviews})"
          end

          cell_buf.puts

          if price && !price.empty?
            cell_buf.puts price
          end

          if merchants && !merchants.empty?
            cell_buf.puts merchants
          end

          cell_buf.flush { |content| content.strip.gsub(/\|/, "\\|").gsub(/\n/, "<br>") }
        }

        buf.puts "| #{cells.join(" | ")} |"

        map[normalize_code(matched_text)] = buf.flush(&:rstrip)
      in { type: "product_entity", matched_text:, product: { title: } }
        map[normalize_code(matched_text)] = "**#{title}**"
      else
        # skip
      end
    }
  end

  def replace_codes(parts, metadata)
    replacement_map = build_code_replacement_map(metadata)
    return parts if replacement_map.empty?

    parts.map { |part|
      case part
      in String
        part.gsub(/\u{E200}\w+\u{E202}.*?\u{E201}/) { |code|
          normalized_code = normalize_code(code)
          replacement_map.fetch(normalized_code) {
            warn "Unrecognizable code found: #{code}"
            code
          }
        }
      else
        part
      end
    }
  end
end

def main
  ChatGPT2Obsidian.run
end

main if __FILE__ == $0
